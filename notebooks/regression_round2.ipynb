{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "  MSE: 2717831151.3651333\n",
      "  R^2 Score: -0.2516456858247138\n",
      "\n",
      "Model: Random Forest\n",
      "  MSE: 1911804141.4293933\n",
      "  R^2 Score: 0.11955479480025966\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     61\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:431\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    430\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:450\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    443\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be equal to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of samples at training time\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    446\u001b[0m         )\n\u001b[1;32m    448\u001b[0m svm_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n\u001b[0;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m libsvm\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    451\u001b[0m     X,\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dual_coef_,\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intercept_,\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    459\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msvm_type,\n\u001b[1;32m    460\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[1;32m    461\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[1;32m    462\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[1;32m    463\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[1;32m    464\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[1;32m    465\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import json\n",
    "\n",
    "#########################################\n",
    "# BLOCK 1: Load and Prepare Data\n",
    "#########################################\n",
    "# Load the CSV file\n",
    "output_csv_path = \"output.csv\"\n",
    "df = pd.read_csv(output_csv_path)\n",
    "\n",
    "# Extract necessary columns\n",
    "df = df[[\"comments_count\", \"like_count\"]].dropna()  # Use only comments_count for regression\n",
    "df[\"comments_count\"] = df[\"comments_count\"].astype(float)  # Ensure numeric type\n",
    "\n",
    "# Split the data\n",
    "X = df[[\"comments_count\"]]  # Feature: comments_count\n",
    "y = df[\"like_count\"]        # Target: like_count\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#########################################\n",
    "# BLOCK 2: Train and Evaluate Multiple Models\n",
    "#########################################\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Regressor (SVR)\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
    "    \"XGBoost Regressor\": xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        seed=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Store metrics for comparison\n",
    "metrics = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Append metrics\n",
    "    metrics.append({\n",
    "        \"Model\": name,\n",
    "        \"MSE\": mse,\n",
    "        \"R^2 Score\": r2\n",
    "    })\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"  MSE: {mse}\")\n",
    "    print(f\"  R^2 Score: {r2}\")\n",
    "    print()\n",
    "\n",
    "#########################################\n",
    "# BLOCK 3: Compare Models\n",
    "#########################################\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.sort_values(by=\"R^2 Score\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(metrics_df)\n",
    "\n",
    "#########################################\n",
    "# BLOCK 4: Best Model for Predictions\n",
    "#########################################\n",
    "# Select the best model (highest RÂ² score)\n",
    "best_model_name = metrics_df.iloc[0][\"Model\"]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Predict on test data for `test-regression-round1.jsonl`\n",
    "test_reg_in_path = \"test-regression-round1.jsonl\"\n",
    "test_reg_out_path = \"test-regression-round1out.jsonl\"\n",
    "\n",
    "output_dict = {}\n",
    "\n",
    "with open(test_reg_in_path, \"r\", encoding=\"utf-8\") as fh:\n",
    "    for line in fh:\n",
    "        sample = json.loads(line)\n",
    "        post_id = sample.get(\"id\", \"NO_ID\")\n",
    "        comments_count = sample.get(\"comments_count\", 0)\n",
    "\n",
    "        # Prepare the feature for prediction\n",
    "        X_test_vec = pd.DataFrame([[comments_count]], columns=[\"comments_count\"])\n",
    "        pred_val = best_model.predict(X_test_vec)[0]\n",
    "        like_count_pred = int(round(pred_val))\n",
    "\n",
    "        output_dict[post_id] = like_count_pred\n",
    "\n",
    "# Write output\n",
    "with open(test_reg_out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Predictions written to: {test_reg_out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
